"""
æ¯æ—¥é¢„æµ‹è„šæœ¬ - å¢é‡æ›´æ–°æ•°æ®å¹¶ç”Ÿæˆé¢„æµ‹Excel

åŠŸèƒ½:
1. å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆåªè·å–æœ€æ–°æ•°æ®è¿½åŠ åˆ°CSVï¼‰
2. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹ä»Šæ—¥ä¸Šæ¶¨æ¦‚ç‡
3. ç”ŸæˆExcelæ–‡ä»¶è®°å½•æ‰€æœ‰è‚¡ç¥¨çš„é¢„æµ‹ç»“æœ

è¿è¡Œ: python predict_today.py

æ•°æ®æº:
- å†å²æ•°æ®ä¸‹è½½: baostock (download_stock_data_baostock.py)
- å¢é‡æ›´æ–°: akshare (æœ¬è„šæœ¬) - æ”¯æŒç›˜ä¸­å®æ—¶æ•°æ®è·å–
"""

import akshare as ak
import pandas as pd
import pickle
import os
from datetime import datetime, timedelta
import warnings
import time

warnings.filterwarnings('ignore')


# ak.stock_zh_a_hist.__globals__['url_stock_zh_a_hist'] = \
#     "http://push2his.eastmoney.com/api/qt/stock/kline/get"

# å…¨å±€å˜é‡ï¼šç¼“å­˜å®æ—¶è¡Œæƒ…æ•°æ®
_spot_data_cache = None
_cache_time = None


def get_spot_data():
    """
    è·å–æ‰€æœ‰Aè‚¡å®æ—¶è¡Œæƒ…ï¼ˆä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è¯·æ±‚ï¼‰

    è¿”å›:
        DataFrame: åŒ…å«æ‰€æœ‰è‚¡ç¥¨å®æ—¶è¡Œæƒ…çš„æ•°æ®
    """
    global _spot_data_cache, _cache_time

    # å¦‚æœç¼“å­˜å­˜åœ¨ä¸”åœ¨5åˆ†é’Ÿå†…ï¼Œç›´æ¥è¿”å›ç¼“å­˜
    if _spot_data_cache is not None and _cache_time is not None:
        if (datetime.now() - _cache_time).total_seconds() < 300:
            return _spot_data_cache

    # å¦åˆ™é‡æ–°è·å–
    try:
        print("  ğŸ“¡ è·å–å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆæ–°æµªæ¥å£ï¼‰...")
        _spot_data_cache = ak.stock_zh_a_spot_em()
        _cache_time = datetime.now()
        print(f"  âœ“ è·å–æˆåŠŸï¼Œå…± {len(_spot_data_cache)} åªè‚¡ç¥¨")
        return _spot_data_cache
    except Exception as e:
        print(f"  âœ— è·å–å®æ—¶è¡Œæƒ…å¤±è´¥: {str(e)[:80]}")
        return None


def update_stock_data_incremental(code, csv_path, spot_data=None, max_days=10):
    """
    ä½¿ç”¨æ–°æµªå®æ—¶è¡Œæƒ… + å†å²æ•°æ®æ¥å£å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®

    ç­–ç•¥:
    1. å¦‚æœCSVå­˜åœ¨ä¸”æœ€æ–°æ—¥æœŸæ˜¯æ˜¨æ—¥ -> ä»å®æ—¶è¡Œæƒ…è·å–ä»Šæ—¥å¼€ç›˜æ•°æ®ï¼Œè¿½åŠ åˆ°CSV
    2. å¦‚æœCSVä¸å­˜åœ¨æˆ–æ•°æ®è¾ƒè€ -> ä½¿ç”¨å†å²æ¥å£ï¼ˆä¼šè§¦å‘é™æµï¼Œä½†æ¬¡æ•°å°‘ï¼‰

    å‚æ•°:
        code: è‚¡ç¥¨ä»£ç  (6ä½ä»£ç ï¼Œå¦‚ '000001', '600036')
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        spot_data: å®æ—¶è¡Œæƒ…DataFrameï¼ˆæå‰è·å–ï¼Œé¿å…é‡å¤è¯·æ±‚ï¼‰
        max_days: æœ€å¤šè·å–æœ€è¿‘å‡ å¤©çš„æ•°æ®

    è¿”å›:
        DataFrame: æ›´æ–°åçš„å®Œæ•´æ•°æ®

    ä¼˜åŠ¿:
        - ä½¿ç”¨æ–°æµªå®æ—¶è¡Œæƒ…æ¥å£ï¼ˆä¸€æ¬¡è¯·æ±‚è·å–æ‰€æœ‰è‚¡ç¥¨ï¼Œé¿å…é¢‘ç¹è¯·æ±‚ï¼‰
        - åªåœ¨å¿…è¦æ—¶æ‰è°ƒç”¨å†å²æ¥å£
        - æ”¯æŒç›˜ä¸­è¿è¡Œï¼ˆ9:30-15:00ï¼‰è·å–å½“æ—¥å®æ—¶æ•°æ®
    """
    df_old = None

    try:
        # 1. è¯»å–ç°æœ‰CSVæ•°æ®
        if os.path.exists(csv_path):
            df_old = pd.read_csv(csv_path)
            df_old['date'] = pd.to_datetime(df_old['date'])
            last_date = df_old['date'].max()
        else:
            df_old = None
            last_date = None

        today = datetime.now().date()
        yesterday = today - timedelta(days=1)

        # 2. åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°
        need_history_data = False
        need_today_data = False

        if last_date is None:
            # CSVä¸å­˜åœ¨ï¼Œéœ€è¦è·å–å†å²æ•°æ®
            need_history_data = True
            start_date = (datetime.now() - timedelta(days=max_days + 5)).strftime('%Y%m%d')
        elif last_date.date() < yesterday:
            # æ•°æ®è¾ƒè€ï¼Œéœ€è¦è·å–å†å²æ•°æ®
            need_history_data = True
            start_date = last_date.strftime('%Y%m%d')
        elif last_date.date() == yesterday:
            # æœ€æ–°æ•°æ®æ˜¯æ˜¨æ—¥ï¼Œåªéœ€è¦è·å–ä»Šæ—¥å®æ—¶æ•°æ®
            need_today_data = True
        else:
            # æ•°æ®å·²æ˜¯æœ€æ–°
            return df_old

        # 3. è·å–ä»Šæ—¥å®æ—¶æ•°æ®ï¼ˆä¼˜å…ˆï¼Œé¿å…é¢‘ç¹è¯·æ±‚ï¼‰
        if need_today_data and spot_data is not None:
            try:
                stock_info = spot_data[spot_data['ä»£ç '] == code]
                if len(stock_info) > 0:
                    row = stock_info.iloc[0]
                    # æå–ä»Šæ—¥æ•°æ®
                    today_data = {
                        'date': pd.Timestamp(today),
                        'open': float(row['ä»Šå¼€']) if pd.notna(row['ä»Šå¼€']) and row['ä»Šå¼€'] != '-' else None,
                        'close': float(row['æœ€æ–°ä»·']) if pd.notna(row['æœ€æ–°ä»·']) and row['æœ€æ–°ä»·'] != '-' else None,
                        'high': float(row['æœ€é«˜']) if pd.notna(row['æœ€é«˜']) and row['æœ€é«˜'] != '-' else None,
                        'low': float(row['æœ€ä½']) if pd.notna(row['æœ€ä½']) and row['æœ€ä½'] != '-' else None,
                        'volume': float(row['æˆäº¤é‡']) if pd.notna(row['æˆäº¤é‡']) and row['æˆäº¤é‡'] != '-' else 0
                    }

                    # å¤„ç†ç›˜ä¸­ä¸å®Œæ•´æ•°æ®
                    if today_data['open'] is not None and today_data['open'] > 0:
                        if today_data['close'] is None or today_data['close'] == 0:
                            today_data['close'] = today_data['open']
                        if today_data['high'] is None or today_data['high'] == 0:
                            today_data['high'] = today_data['open']
                        if today_data['low'] is None or today_data['low'] == 0:
                            today_data['low'] = today_data['open']
                        if today_data['volume'] == 0:
                            today_data['volume'] = 1

                        # è¿½åŠ ä»Šæ—¥æ•°æ®
                        df_today = pd.DataFrame([today_data])
                        df_merged = pd.concat([df_old, df_today], ignore_index=True)
                        df_merged = df_merged.sort_values('date').reset_index(drop=True)

                        # ä¿å­˜
                        df_merged.to_csv(csv_path, index=False, encoding='utf-8-sig')
                        return df_merged
            except Exception as e:
                print(f"  âš ï¸  {code} å®æ—¶æ•°æ®è·å–å¤±è´¥ï¼Œå°è¯•å†å²æ¥å£: {str(e)[:50]}")
                need_history_data = True

        # 4. å¦‚æœéœ€è¦å†å²æ•°æ®ï¼Œä½¿ç”¨å†å²æ¥å£ï¼ˆä¼šè§¦å‘é™æµï¼Œä½†æ¬¡æ•°å°‘ï¼‰
        if need_history_data:
            end_date = datetime.now().strftime('%Y%m%d')

            # æ·»åŠ å»¶æ—¶
            time.sleep(0.3)

            df_new = ak.stock_zh_a_hist(
                symbol=code,
                period="daily",
                start_date=start_date,
                end_date=end_date,
                adjust="qfq"  # å‰å¤æƒ
            )

            if df_new is None or len(df_new) == 0:
                return df_old

            # æ•°æ®æ¸…æ´—ï¼šæ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'æ—¥æœŸ': 'date',
                'å¼€ç›˜': 'open',
                'æ”¶ç›˜': 'close',
                'æœ€é«˜': 'high',
                'æœ€ä½': 'low',
                'æˆäº¤é‡': 'volume'
            }

            df_new = df_new.rename(columns=column_mapping)
            required_cols = ['date', 'open', 'high', 'low', 'close', 'volume']
            df_new = df_new[required_cols].copy()
            df_new['date'] = pd.to_datetime(df_new['date'])

            for col in ['open', 'high', 'low', 'close', 'volume']:
                df_new[col] = pd.to_numeric(df_new[col], errors='coerce')

            # å¤„ç†ç›˜ä¸­ä¸å®Œæ•´æ•°æ®
            for idx, row in df_new.iterrows():
                if row['date'].date() == today and pd.notna(row['open']):
                    if pd.isna(row['close']) or row['close'] == 0:
                        df_new.loc[idx, 'close'] = row['open']
                    if pd.isna(row['high']) or row['high'] == 0:
                        df_new.loc[idx, 'high'] = row['open']
                    if pd.isna(row['low']) or row['low'] == 0:
                        df_new.loc[idx, 'low'] = row['open']
                    if pd.isna(row['volume']) or row['volume'] == 0:
                        df_new.loc[idx, 'volume'] = 1

            df_new = df_new.dropna(subset=['open', 'close'])
            df_new = df_new[df_new['open'] > 0].copy()

            if len(df_new) == 0:
                return df_old

            # åˆå¹¶æ•°æ®
            if df_old is not None:
                df_merged = pd.concat([df_old, df_new], ignore_index=True)
                df_merged = df_merged.drop_duplicates(subset=['date'], keep='last')
                df_merged = df_merged.sort_values('date').reset_index(drop=True)
            else:
                df_merged = df_new.sort_values('date').reset_index(drop=True)

            # ä¿å­˜
            df_merged.to_csv(csv_path, index=False, encoding='utf-8-sig')
            return df_merged

        return df_old

    except Exception as e:
        print(f"  âœ— {code} æ›´æ–°å¤±è´¥: {str(e)[:80]}")
        if df_old is not None:
            return df_old
        return None


def calculate_features(df, for_training=False):
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ï¼ˆå…±10ä¸ªç‰¹å¾ï¼Œä¸final_strategy.pyå®Œå…¨ä¸€è‡´ï¼‰

    - å†å²ç‰¹å¾ï¼šä½¿ç”¨æˆªè‡³æ˜¨æ—¥æ”¶ç›˜çš„æ•°æ®ï¼ˆå¼€ç›˜æ—¶å·²çŸ¥ï¼‰
    - å¼€ç›˜ç‰¹å¾ï¼šä½¿ç”¨å½“æ—¥å¼€ç›˜ä»·ï¼ˆå¼€ç›˜æ—¶å·²çŸ¥ï¼‰
    - ç¡®ä¿æ‰€æœ‰ç‰¹å¾åœ¨å¼€ç›˜æ—¶éƒ½å¯è·å¾—ï¼Œæ— æ—¶é—´ç©¿è¶Š

    å‚æ•°:
        df: åŒ…å«OHLCVæ•°æ®çš„DataFrame
        for_training: æ˜¯å¦ç”¨äºè®­ç»ƒï¼ˆTrueæ—¶è®¡ç®—æ ‡ç­¾ï¼ŒFalseæ—¶ä¸è®¡ç®—ï¼‰

    è¿”å›:
        df: æ·»åŠ äº†ç‰¹å¾åˆ—å’Œæ ‡ç­¾åˆ—çš„DataFrame

    ç‰¹å¾è¯´æ˜ï¼ˆå‰8ä¸ªä¸ºå†å²ç‰¹å¾ï¼Œå2ä¸ªä¸ºå¼€ç›˜ç‰¹å¾ï¼‰:
        å†å²ç‰¹å¾ï¼ˆåŸºäºæ˜¨æ—¥åŠä¹‹å‰æ•°æ®ï¼‰:
        1. return_1d_prev: æ˜¨æ—¥æ”¶ç›Šç‡ï¼ˆçŸ­æœŸåŠ¨é‡ï¼‰
        2. return_5d_prev: 5æ—¥æ”¶ç›Šç‡æˆªè‡³æ˜¨æ—¥ï¼ˆä¸­æœŸåŠ¨é‡ï¼‰
        3. return_10d_prev: 10æ—¥æ”¶ç›Šç‡æˆªè‡³æ˜¨æ—¥ï¼ˆé•¿æœŸåŠ¨é‡ï¼‰
        4. ma_ratio_5_20_prev: æ˜¨æ—¥5æ—¥å‡çº¿/20æ—¥å‡çº¿ï¼ˆå‡çº¿ä½ç½®ï¼‰
        5. volume_ratio_prev: æ˜¨æ—¥æˆäº¤é‡/5æ—¥å‡é‡ï¼ˆé‡èƒ½å˜åŒ–ï¼‰
        6. rsi_prev: æ˜¨æ—¥RSIæŒ‡æ ‡ï¼ˆè¶…ä¹°è¶…å–ï¼‰
        7. volatility_prev: æ˜¨æ—¥æ³¢åŠ¨ç‡ï¼ˆé£é™©æ°´å¹³ï¼‰
        8. bb_position_prev: æ˜¨æ—¥å¸ƒæ—å¸¦ä½ç½®ï¼ˆä»·æ ¼ç›¸å¯¹ä½ç½®ï¼‰

        å¼€ç›˜ç‰¹å¾ï¼ˆåŸºäºå½“æ—¥å¼€ç›˜ä»·ï¼‰:
        9. open_gap: å¼€ç›˜è·³ç©º = ä»Šå¼€ç›˜/æ˜¨æ”¶ç›˜ - 1ï¼ˆéš”å¤œå˜åŒ–ï¼‰
        10. open_vs_ma5: å¼€ç›˜ä»·/æ˜¨æ—¥5æ—¥å‡çº¿ - 1ï¼ˆå¼€ç›˜å¼ºåº¦ï¼‰

    æ ‡ç­¾å®šä¹‰ï¼ˆä»…è®­ç»ƒæ—¶è®¡ç®—ï¼‰:
        label=1: æœªæ¥5æ—¥æ¶¨å¹…>3% (æ­£æ ·æœ¬)
        label=0: æœªæ¥5æ—¥æ¶¨å¹…â‰¤3% (è´Ÿæ ·æœ¬)
    """
    # === ç¬¬ä¸€éƒ¨åˆ†ï¼šè®¡ç®—åŸå§‹æŒ‡æ ‡ï¼ˆåŸºäºæ”¶ç›˜ä»·ï¼‰ ===

    # ä»·æ ¼æ”¶ç›Šç‡
    return_1d = df['close'].pct_change(1)
    return_5d = df['close'].pct_change(5)
    return_10d = df['close'].pct_change(10)

    # å‡çº¿
    ma5 = df['close'].rolling(5).mean()
    ma10 = df['close'].rolling(10).mean()
    ma20 = df['close'].rolling(20).mean()
    ma_ratio_5_20 = ma5 / ma20

    # æˆäº¤é‡
    volume_ma5 = df['volume'].rolling(5).mean()
    volume_ratio = df['volume'] / volume_ma5

    # RSIæŒ‡æ ‡
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))

    # æ³¢åŠ¨ç‡
    volatility = return_1d.rolling(20).std()

    # å¸ƒæ—å¸¦
    bb_middle = df['close'].rolling(20).mean()
    bb_std = df['close'].rolling(20).std()
    bb_upper = bb_middle + 2 * bb_std
    bb_lower = bb_middle - 2 * bb_std
    bb_position = (df['close'] - bb_lower) / (bb_upper - bb_lower)

    # === ç¬¬äºŒéƒ¨åˆ†ï¼šå‘ååç§»1å¤©ï¼ˆè®©ç‰¹å¾å¯¹é½åˆ°"æˆªè‡³æ˜¨æ—¥"ï¼‰ ===

    df['return_1d_prev'] = return_1d.shift(1)      # æ˜¨æ—¥æ”¶ç›Šç‡
    df['return_5d_prev'] = return_5d.shift(1)      # 5æ—¥æ”¶ç›Šç‡ï¼ˆæˆªè‡³æ˜¨æ—¥ï¼‰
    df['return_10d_prev'] = return_10d.shift(1)    # 10æ—¥æ”¶ç›Šç‡ï¼ˆæˆªè‡³æ˜¨æ—¥ï¼‰
    df['ma_ratio_5_20_prev'] = ma_ratio_5_20.shift(1)  # æ˜¨æ—¥å‡çº¿æ¯”
    df['volume_ratio_prev'] = volume_ratio.shift(1)    # æ˜¨æ—¥é‡æ¯”
    df['rsi_prev'] = rsi.shift(1)                  # æ˜¨æ—¥RSI
    df['volatility_prev'] = volatility.shift(1)    # æ˜¨æ—¥æ³¢åŠ¨ç‡
    df['bb_position_prev'] = bb_position.shift(1)  # æ˜¨æ—¥å¸ƒæ—å¸¦ä½ç½®

    # === ç¬¬ä¸‰éƒ¨åˆ†ï¼šè®¡ç®—å¼€ç›˜ä»·ç‰¹å¾ï¼ˆå½“æ—¥å¼€ç›˜æ—¶å¯è·å¾—ï¼‰ ===

    df['open_gap'] = df['open'] / df['close'].shift(1) - 1  # å¼€ç›˜è·³ç©º
    df['open_vs_ma5'] = df['open'] / ma5.shift(1) - 1       # å¼€ç›˜ä»·ç›¸å¯¹å‡çº¿ä½ç½®

    # === ç¬¬å››éƒ¨åˆ†ï¼šæ ‡ç­¾ï¼ˆæœªæ¥5æ—¥æ¶¨å¹…ï¼‰ - ä»…è®­ç»ƒæ—¶è®¡ç®— ===

    if for_training:
        df['future_return'] = df['close'].shift(-5) / df['close'] - 1
        df['label'] = (df['future_return'] > 0.03).astype(int)

    return df


def predict_today():
    """ä¸»å‡½æ•°ï¼šå¢é‡æ›´æ–°æ•°æ®å¹¶é¢„æµ‹"""

    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ¯æ—¥è‚¡ç¥¨ä¸Šæ¶¨æ¦‚ç‡é¢„æµ‹")
    print(f"{'='*80}")
    print(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # 1. æ£€æŸ¥å¹¶åŠ è½½æ¨¡å‹
    model_path = 'rf_model.pkl'
    if not os.path.exists(model_path):
        print(f"\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print(f"è¯·å…ˆè¿è¡Œ final_strategy.py è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹")
        return

    print(f"\n[1/4] ğŸ“¦ åŠ è½½æ¨¡å‹...")
    with open(model_path, 'rb') as f:
        model_data = pickle.load(f)
        model = model_data['model']
        feature_cols = model_data['feature_cols']
        stock_pool = model_data['stock_pool']

    print(f"  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"  âœ“ è‚¡ç¥¨æ± : {len(stock_pool)} åª")
    print(f"  âœ“ ç‰¹å¾æ•°: {len(feature_cols)} ä¸ª")

    # 2. AkShareæ— éœ€ç™»å½•ï¼Œç›´æ¥å¼€å§‹æ›´æ–°
    print(f"\n[2/4] ğŸ”Œ ä½¿ç”¨AkShareæ•°æ®æºï¼ˆæ”¯æŒç›˜ä¸­å®æ—¶æ•°æ®ï¼‰...")
    print(f"  âœ“ AkShareæ— éœ€ç™»å½•ï¼Œç›´æ¥è·å–æ•°æ®")

    try:
        # 3. å¢é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        print(f"\n[3/4] ğŸ“ˆ å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®...")
        data_dir = 'stock_data'

        # æ˜¾ç¤ºæ¨¡å‹æœŸæœ›çš„ç‰¹å¾åˆ—è¡¨
        print(f"\n  æ¨¡å‹æœŸæœ›ç‰¹å¾ ({len(feature_cols)} ä¸ª):")
        for i, feat in enumerate(feature_cols, 1):
            print(f"    {i}. {feat}")
        print()

        # ä¼˜å…ˆè·å–å®æ—¶è¡Œæƒ…ï¼ˆä¸€æ¬¡æ€§è·å–æ‰€æœ‰è‚¡ç¥¨ï¼Œé¿å…é¢‘ç¹è¯·æ±‚ï¼‰
        spot_data = get_spot_data()

        predictions = []
        success_count = 0
        fail_count = 0
        first_error_shown = False  # æ ‡è®°æ˜¯å¦å·²æ˜¾ç¤ºç¬¬ä¸€ä¸ªé”™è¯¯

        total = len(stock_pool)
        for idx, (code, name) in enumerate(stock_pool.items(), 1):
            # ä½¿ç”¨ä¸ä¸‹è½½è„šæœ¬ä¸€è‡´çš„å‘½åæ ¼å¼: {code}_{name}.csv
            csv_path = os.path.join(data_dir, f'{code}_{name}.csv')

            # æ˜¾ç¤ºè¿›åº¦
            if idx % 10 == 0 or idx == 1:
                print(f"  è¿›åº¦: {idx}/{total} ({idx/total*100:.1f}%) - {code} {name}")

            # å¢é‡æ›´æ–°æ•°æ®ï¼ˆä¼ å…¥å®æ—¶è¡Œæƒ…æ•°æ®ï¼Œé¿å…é‡å¤è¯·æ±‚ï¼‰
            df = update_stock_data_incremental(code, csv_path, spot_data=spot_data, max_days=10)

            if df is None or len(df) < 60:
                fail_count += 1
                if not first_error_shown:
                    print(f"\n  âš ï¸  é¦–ä¸ªå¤±è´¥æ¡ˆä¾‹: {code} {name}")
                    print(f"      åŸå› : æ•°æ®ä¸è¶³")
                    if df is None:
                        print(f"      è¯¦æƒ…: CSVæ–‡ä»¶è¯»å–å¤±è´¥æˆ–æ— æ•°æ®")
                    else:
                        print(f"      è¯¦æƒ…: æ•°æ®è¡Œæ•° {len(df)} < 60 (ä¸è¶³ä»¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡)")
                    print(f"      æ–‡ä»¶: {csv_path}")
                    first_error_shown = True
                continue

            # è®¡ç®—ç‰¹å¾
            df = calculate_features(df, for_training=False)

            # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in feature_cols if col not in df.columns]
            if missing_cols:
                fail_count += 1
                if not first_error_shown:
                    print(f"\n  âš ï¸  é¦–ä¸ªå¤±è´¥æ¡ˆä¾‹: {code} {name}")
                    print(f"      åŸå› : ç¼ºå°‘ç‰¹å¾åˆ—")
                    print(f"      ç¼ºå¤±ç‰¹å¾: {missing_cols}")
                    print(f"      è®¡ç®—åç‰¹å¾æ•°: {len(df.columns)}")
                    first_error_shown = True
                continue

            df = df.dropna(subset=feature_cols)

            if len(df) == 0:
                fail_count += 1
                if not first_error_shown:
                    print(f"\n  âš ï¸  é¦–ä¸ªå¤±è´¥æ¡ˆä¾‹: {code} {name}")
                    print(f"      åŸå› : ç‰¹å¾è®¡ç®—åæ‰€æœ‰è¡Œéƒ½åŒ…å«NaN")
                    first_error_shown = True
                continue

            # ä½¿ç”¨æœ€æ–°ä¸€è¡Œæ•°æ®é¢„æµ‹
            latest = df.iloc[-1]
            X = latest[feature_cols].values.reshape(1, -1)

            # é¢„æµ‹æ¦‚ç‡
            prob = model.predict_proba(X)[0][1]

            predictions.append({
                'è‚¡ç¥¨ä»£ç ': code,
                'è‚¡ç¥¨åç§°': name,
                'é¢„æµ‹æ¦‚ç‡': prob,
                'æ•°æ®æ—¥æœŸ': latest['date'].strftime('%Y-%m-%d'),
                'æ”¶ç›˜ä»·': latest['close'],
                'å¼€ç›˜ä»·': latest['open'],
                'æ˜¨æ—¥æ¶¨å¹…': latest.get('return_1d_prev', 0),
                '5æ—¥æ¶¨å¹…': latest.get('return_5d_prev', 0),
                '10æ—¥æ¶¨å¹…': latest.get('return_10d_prev', 0),
                'å¼€ç›˜è·³ç©º': latest.get('open_gap', 0),
                'RSI': latest.get('rsi_prev', 50),
                'é‡æ¯”': latest.get('volume_ratio_prev', 1),
                'å¸ƒæ—å¸¦ä½ç½®': latest.get('bb_position_prev', 0.5),
                'æ³¢åŠ¨ç‡': latest.get('volatility_prev', 0)
            })

            success_count += 1

            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæˆåŠŸæ¡ˆä¾‹çš„è¯¦ç»†ä¿¡æ¯
            if success_count == 1:
                print(f"\n  âœ… é¦–ä¸ªæˆåŠŸæ¡ˆä¾‹: {code} {name}")
                print(f"      CSVè¡Œæ•°: {len(df)}")
                print(f"      æœ€æ–°æ—¥æœŸ: {latest['date'].strftime('%Y-%m-%d')}")
                print(f"      é¢„æµ‹æ¦‚ç‡: {prob:.2%}\n")

        print(f"\n  âœ“ æ•°æ®æ›´æ–°å®Œæˆ: æˆåŠŸ {success_count}/{total}, å¤±è´¥ {fail_count}")

    finally:
        pass  # AkShareæ— éœ€ç™»å‡º

    if len(predictions) == 0:
        print(f"\nâŒ æ— æœ‰æ•ˆé¢„æµ‹æ•°æ®")
        return

    # 4. ç”ŸæˆExcelæ–‡ä»¶
    print(f"\n[4/4] ğŸ“Š ç”Ÿæˆé¢„æµ‹Excel...")

    df_predictions = pd.DataFrame(predictions)
    df_predictions = df_predictions.sort_values('é¢„æµ‹æ¦‚ç‡', ascending=False)
    df_predictions['æ’å'] = range(1, len(df_predictions) + 1)

    # è°ƒæ•´åˆ—é¡ºåº
    cols = ['æ’å', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'é¢„æµ‹æ¦‚ç‡', 'æ•°æ®æ—¥æœŸ', 'æ”¶ç›˜ä»·', 'å¼€ç›˜ä»·',
            'å¼€ç›˜è·³ç©º', 'æ˜¨æ—¥æ¶¨å¹…', '5æ—¥æ¶¨å¹…', '10æ—¥æ¶¨å¹…', 'RSI', 'é‡æ¯”', 'å¸ƒæ—å¸¦ä½ç½®', 'æ³¢åŠ¨ç‡']
    df_predictions = df_predictions[cols]

    # ä¿å­˜åˆ°Excel
    output_file = f"stock_predictions_{datetime.now().strftime('%Y%m%d')}.xlsx"

    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # å†™å…¥å®Œæ•´é¢„æµ‹ç»“æœ
        df_predictions.to_excel(writer, sheet_name='å®Œæ•´é¢„æµ‹', index=False)

        # å†™å…¥é«˜æ¦‚ç‡è‚¡ç¥¨ï¼ˆâ‰¥60%ï¼‰
        df_high = df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.60]
        if len(df_high) > 0:
            df_high.to_excel(writer, sheet_name='é«˜æ¦‚ç‡è‚¡ç¥¨(â‰¥60%)', index=False)

        # å†™å…¥ä¸­ç­‰æ¦‚ç‡è‚¡ç¥¨ï¼ˆ55%-60%ï¼‰
        df_medium = df_predictions[(df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.55) &
                                   (df_predictions['é¢„æµ‹æ¦‚ç‡'] < 0.60)]
        if len(df_medium) > 0:
            df_medium.to_excel(writer, sheet_name='ä¸­ç­‰æ¦‚ç‡è‚¡ç¥¨(55-60%)', index=False)

    print(f"  âœ“ Excelå·²ç”Ÿæˆ: {output_file}")

    # 5. æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
    print(f"\n{'='*80}")
    print(f"ğŸ“Š é¢„æµ‹ç»“æœæ‘˜è¦")
    print(f"{'='*80}")
    print(f"æ€»è‚¡ç¥¨æ•°: {len(df_predictions)}")
    print(f"å¹³å‡é¢„æµ‹æ¦‚ç‡: {df_predictions['é¢„æµ‹æ¦‚ç‡'].mean():.2%}")
    print(f"")
    print(f"æ¦‚ç‡åˆ†å¸ƒ:")
    print(f"  â‰¥ 65%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.65])} åª")
    print(f"  â‰¥ 60%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.60])} åª")
    print(f"  â‰¥ 55%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.55])} åª")
    print(f"  â‰¥ 50%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.50])} åª")

    # æ˜¾ç¤ºTop 10
    print(f"\n{'='*80}")
    print(f"ğŸ† Top 10 é¢„æµ‹è‚¡ç¥¨")
    print(f"{'='*80}")
    print(f"{'æ’å':<6} {'ä»£ç ':<10} {'åç§°':<12} {'æ¦‚ç‡':<10} {'å¼€ç›˜ä»·':<10} {'å¼€ç›˜è·³ç©º':<10}")
    print(f"{'-'*80}")

    for _, row in df_predictions.head(10).iterrows():
        print(f"{row['æ’å']:<6} {row['è‚¡ç¥¨ä»£ç ']:<10} {row['è‚¡ç¥¨åç§°']:<12} "
              f"{row['é¢„æµ‹æ¦‚ç‡']:>8.2%} {row['å¼€ç›˜ä»·']:>9.2f} {row['å¼€ç›˜è·³ç©º']:>9.2%}")

    print(f"\n{'='*80}")
    print(f"âœ… é¢„æµ‹å®Œæˆï¼")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    predict_today()
