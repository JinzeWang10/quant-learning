"""
æ¯æ—¥é¢„æµ‹è„šæœ¬ - å¢é‡æ›´æ–°æ•°æ®å¹¶ç”Ÿæˆé¢„æµ‹Excel

åŠŸèƒ½:
1. å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆåªè·å–æœ€æ–°æ•°æ®è¿½åŠ åˆ°CSVï¼‰
2. ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹ä»Šæ—¥ä¸Šæ¶¨æ¦‚ç‡
3. ç”ŸæˆExcelæ–‡ä»¶è®°å½•æ‰€æœ‰è‚¡ç¥¨çš„é¢„æµ‹ç»“æœ

è¿è¡Œ: python predict_today.py
"""

import baostock as bs
import pandas as pd
import pickle
import os
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings('ignore')


def format_stock_code(code):
    """è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼"""
    if code.startswith('6'):
        return f'sh.{code}'
    else:
        return f'sz.{code}'


def update_stock_data_incremental(code, csv_path, max_days=10):
    """
    å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®ï¼ˆåªè·å–æœ€æ–°æ•°æ®è¿½åŠ åˆ°CSVï¼‰

    å‚æ•°:
        code: è‚¡ç¥¨ä»£ç 
        csv_path: CSVæ–‡ä»¶è·¯å¾„
        max_days: æœ€å¤šè·å–æœ€è¿‘å‡ å¤©çš„æ•°æ®

    è¿”å›:
        DataFrame: æ›´æ–°åçš„å®Œæ•´æ•°æ®

    æ³¨æ„:
        - æ”¯æŒç›˜ä¸­è¿è¡Œï¼ˆ9:30-15:00ï¼‰
        - å¦‚æœä»Šæ—¥æ•°æ®ä¸å®Œæ•´ï¼ˆåªæœ‰å¼€ç›˜ä»·ï¼‰ï¼Œä¼šç”¨å¼€ç›˜ä»·ä¸´æ—¶å¡«å……close/high/low
        - è¿™ä¸å½±å“é¢„æµ‹ï¼Œå› ä¸ºç‰¹å¾è®¡ç®—åªä¾èµ–ï¼š
          1) å†å²ç‰¹å¾ï¼šä½¿ç”¨æ˜¨æ—¥åŠä¹‹å‰æ•°æ®ï¼ˆshift(1)ï¼‰
          2) å¼€ç›˜ç‰¹å¾ï¼šåªéœ€è¦ä»Šæ—¥å¼€ç›˜ä»·
    """
    try:
        # 1. è¯»å–ç°æœ‰CSVæ•°æ®
        if os.path.exists(csv_path):
            df_old = pd.read_csv(csv_path)
            df_old['date'] = pd.to_datetime(df_old['date'])
            last_date = df_old['date'].max()

            # è®¡ç®—éœ€è¦è·å–çš„èµ·å§‹æ—¥æœŸï¼ˆä»æœ€åä¸€å¤©çš„ä¸‹ä¸€å¤©å¼€å§‹ï¼‰
            start_date = (last_date + timedelta(days=1)).strftime('%Y-%m-%d')
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·å–æœ€è¿‘max_dayså¤©çš„æ•°æ®
            df_old = None
            start_date = (datetime.now() - timedelta(days=max_days + 5)).strftime('%Y-%m-%d')

        end_date = datetime.now().strftime('%Y-%m-%d')

        # å¦‚æœå·²æ˜¯æœ€æ–°ï¼Œç›´æ¥è¿”å›
        if df_old is not None and start_date > end_date:
            return df_old

        # 2. è·å–å¢é‡æ•°æ®
        bs_code = format_stock_code(code)
        rs = bs.query_history_k_data_plus(
            bs_code,
            "date,open,high,low,close,volume",
            start_date=start_date,
            end_date=end_date,
            frequency="d",
            adjustflag="3"  # åå¤æƒ
        )

        if rs.error_code != '0':
            return df_old

        # è·å–æ–°æ•°æ®
        data_list = []
        while rs.error_code == '0' and rs.next():
            data_list.append(rs.get_row_data())

        if not data_list:
            return df_old

        # è½¬æ¢ä¸ºDataFrame
        df_new = pd.DataFrame(data_list, columns=rs.fields)
        df_new['date'] = pd.to_datetime(df_new['date'])

        for col in ['open', 'high', 'low', 'close', 'volume']:
            df_new[col] = pd.to_numeric(df_new[col], errors='coerce')

        # å¤„ç†ç›˜ä¸­ä¸å®Œæ•´æ•°æ®ï¼šå¦‚æœæ˜¯ä»Šæ—¥æ•°æ®ä¸”åªæœ‰å¼€ç›˜ä»·ï¼Œç”¨å¼€ç›˜ä»·å¡«å……æ”¶ç›˜ä»·
        today = datetime.now().date()
        for idx, row in df_new.iterrows():
            if row['date'].date() == today and pd.notna(row['open']):
                # ç›˜ä¸­æ•°æ®ï¼šç”¨å¼€ç›˜ä»·å¡«å……å…¶ä»–ä»·æ ¼ï¼ˆä¸´æ—¶å€¼ï¼Œä¸å½±å“ç‰¹å¾è®¡ç®—ï¼‰
                if pd.isna(row['close']) or row['close'] == 0:
                    df_new.loc[idx, 'close'] = row['open']
                if pd.isna(row['high']) or row['high'] == 0:
                    df_new.loc[idx, 'high'] = row['open']
                if pd.isna(row['low']) or row['low'] == 0:
                    df_new.loc[idx, 'low'] = row['open']
                if pd.isna(row['volume']) or row['volume'] == 0:
                    df_new.loc[idx, 'volume'] = 1  # è®¾ç½®ä¸º1é¿å…é™¤é›¶é”™è¯¯

        df_new = df_new.dropna(subset=['open', 'close'])  # åªè¦æ±‚æœ‰å¼€ç›˜ä»·å’Œæ”¶ç›˜ä»·
        df_new = df_new[df_new['open'] > 0].copy()  # å¼€ç›˜ä»·å¿…é¡»å¤§äº0

        if len(df_new) == 0:
            return df_old

        # 3. åˆå¹¶æ•°æ®
        if df_old is not None:
            df_merged = pd.concat([df_old, df_new], ignore_index=True)
            # å»é‡ï¼ˆé˜²æ­¢é‡å¤æ—¥æœŸï¼‰
            df_merged = df_merged.drop_duplicates(subset=['date'], keep='last')
            df_merged = df_merged.sort_values('date').reset_index(drop=True)
        else:
            df_merged = df_new

        # 4. ä¿å­˜æ›´æ–°åçš„æ•°æ®
        df_merged.to_csv(csv_path, index=False, encoding='utf-8-sig')

        return df_merged

    except Exception as e:
        print(f"  âœ— {code} æ›´æ–°å¤±è´¥: {str(e)[:50]}")
        # å¦‚æœæ›´æ–°å¤±è´¥ï¼Œè¿”å›åŸæ•°æ®
        if df_old is not None:
            return df_old
        return None


def calculate_features(df, for_training=False):
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾ï¼ˆå…±10ä¸ªç‰¹å¾ï¼Œä¸final_strategy.pyå®Œå…¨ä¸€è‡´ï¼‰

    - å†å²ç‰¹å¾ï¼šä½¿ç”¨æˆªè‡³æ˜¨æ—¥æ”¶ç›˜çš„æ•°æ®ï¼ˆå¼€ç›˜æ—¶å·²çŸ¥ï¼‰
    - å¼€ç›˜ç‰¹å¾ï¼šä½¿ç”¨å½“æ—¥å¼€ç›˜ä»·ï¼ˆå¼€ç›˜æ—¶å·²çŸ¥ï¼‰
    - ç¡®ä¿æ‰€æœ‰ç‰¹å¾åœ¨å¼€ç›˜æ—¶éƒ½å¯è·å¾—ï¼Œæ— æ—¶é—´ç©¿è¶Š

    å‚æ•°:
        df: åŒ…å«OHLCVæ•°æ®çš„DataFrame
        for_training: æ˜¯å¦ç”¨äºè®­ç»ƒï¼ˆTrueæ—¶è®¡ç®—æ ‡ç­¾ï¼ŒFalseæ—¶ä¸è®¡ç®—ï¼‰

    è¿”å›:
        df: æ·»åŠ äº†ç‰¹å¾åˆ—å’Œæ ‡ç­¾åˆ—çš„DataFrame

    ç‰¹å¾è¯´æ˜ï¼ˆå‰8ä¸ªä¸ºå†å²ç‰¹å¾ï¼Œå2ä¸ªä¸ºå¼€ç›˜ç‰¹å¾ï¼‰:
        å†å²ç‰¹å¾ï¼ˆåŸºäºæ˜¨æ—¥åŠä¹‹å‰æ•°æ®ï¼‰:
        1. return_1d_prev: æ˜¨æ—¥æ”¶ç›Šç‡ï¼ˆçŸ­æœŸåŠ¨é‡ï¼‰
        2. return_5d_prev: 5æ—¥æ”¶ç›Šç‡æˆªè‡³æ˜¨æ—¥ï¼ˆä¸­æœŸåŠ¨é‡ï¼‰
        3. return_10d_prev: 10æ—¥æ”¶ç›Šç‡æˆªè‡³æ˜¨æ—¥ï¼ˆé•¿æœŸåŠ¨é‡ï¼‰
        4. ma_ratio_5_20_prev: æ˜¨æ—¥5æ—¥å‡çº¿/20æ—¥å‡çº¿ï¼ˆå‡çº¿ä½ç½®ï¼‰
        5. volume_ratio_prev: æ˜¨æ—¥æˆäº¤é‡/5æ—¥å‡é‡ï¼ˆé‡èƒ½å˜åŒ–ï¼‰
        6. rsi_prev: æ˜¨æ—¥RSIæŒ‡æ ‡ï¼ˆè¶…ä¹°è¶…å–ï¼‰
        7. volatility_prev: æ˜¨æ—¥æ³¢åŠ¨ç‡ï¼ˆé£é™©æ°´å¹³ï¼‰
        8. bb_position_prev: æ˜¨æ—¥å¸ƒæ—å¸¦ä½ç½®ï¼ˆä»·æ ¼ç›¸å¯¹ä½ç½®ï¼‰

        å¼€ç›˜ç‰¹å¾ï¼ˆåŸºäºå½“æ—¥å¼€ç›˜ä»·ï¼‰:
        9. open_gap: å¼€ç›˜è·³ç©º = ä»Šå¼€ç›˜/æ˜¨æ”¶ç›˜ - 1ï¼ˆéš”å¤œå˜åŒ–ï¼‰
        10. open_vs_ma5: å¼€ç›˜ä»·/æ˜¨æ—¥5æ—¥å‡çº¿ - 1ï¼ˆå¼€ç›˜å¼ºåº¦ï¼‰

    æ ‡ç­¾å®šä¹‰ï¼ˆä»…è®­ç»ƒæ—¶è®¡ç®—ï¼‰:
        label=1: æœªæ¥5æ—¥æ¶¨å¹…>3% (æ­£æ ·æœ¬)
        label=0: æœªæ¥5æ—¥æ¶¨å¹…â‰¤3% (è´Ÿæ ·æœ¬)
    """
    # === ç¬¬ä¸€éƒ¨åˆ†ï¼šè®¡ç®—åŸå§‹æŒ‡æ ‡ï¼ˆåŸºäºæ”¶ç›˜ä»·ï¼‰ ===

    # ä»·æ ¼æ”¶ç›Šç‡
    return_1d = df['close'].pct_change(1)
    return_5d = df['close'].pct_change(5)
    return_10d = df['close'].pct_change(10)

    # å‡çº¿
    ma5 = df['close'].rolling(5).mean()
    ma10 = df['close'].rolling(10).mean()
    ma20 = df['close'].rolling(20).mean()
    ma_ratio_5_20 = ma5 / ma20

    # æˆäº¤é‡
    volume_ma5 = df['volume'].rolling(5).mean()
    volume_ratio = df['volume'] / volume_ma5

    # RSIæŒ‡æ ‡
    delta = df['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))

    # æ³¢åŠ¨ç‡
    volatility = return_1d.rolling(20).std()

    # å¸ƒæ—å¸¦
    bb_middle = df['close'].rolling(20).mean()
    bb_std = df['close'].rolling(20).std()
    bb_upper = bb_middle + 2 * bb_std
    bb_lower = bb_middle - 2 * bb_std
    bb_position = (df['close'] - bb_lower) / (bb_upper - bb_lower)

    # === ç¬¬äºŒéƒ¨åˆ†ï¼šå‘ååç§»1å¤©ï¼ˆè®©ç‰¹å¾å¯¹é½åˆ°"æˆªè‡³æ˜¨æ—¥"ï¼‰ ===

    df['return_1d_prev'] = return_1d.shift(1)      # æ˜¨æ—¥æ”¶ç›Šç‡
    df['return_5d_prev'] = return_5d.shift(1)      # 5æ—¥æ”¶ç›Šç‡ï¼ˆæˆªè‡³æ˜¨æ—¥ï¼‰
    df['return_10d_prev'] = return_10d.shift(1)    # 10æ—¥æ”¶ç›Šç‡ï¼ˆæˆªè‡³æ˜¨æ—¥ï¼‰
    df['ma_ratio_5_20_prev'] = ma_ratio_5_20.shift(1)  # æ˜¨æ—¥å‡çº¿æ¯”
    df['volume_ratio_prev'] = volume_ratio.shift(1)    # æ˜¨æ—¥é‡æ¯”
    df['rsi_prev'] = rsi.shift(1)                  # æ˜¨æ—¥RSI
    df['volatility_prev'] = volatility.shift(1)    # æ˜¨æ—¥æ³¢åŠ¨ç‡
    df['bb_position_prev'] = bb_position.shift(1)  # æ˜¨æ—¥å¸ƒæ—å¸¦ä½ç½®

    # === ç¬¬ä¸‰éƒ¨åˆ†ï¼šè®¡ç®—å¼€ç›˜ä»·ç‰¹å¾ï¼ˆå½“æ—¥å¼€ç›˜æ—¶å¯è·å¾—ï¼‰ ===

    df['open_gap'] = df['open'] / df['close'].shift(1) - 1  # å¼€ç›˜è·³ç©º
    df['open_vs_ma5'] = df['open'] / ma5.shift(1) - 1       # å¼€ç›˜ä»·ç›¸å¯¹å‡çº¿ä½ç½®

    # === ç¬¬å››éƒ¨åˆ†ï¼šæ ‡ç­¾ï¼ˆæœªæ¥5æ—¥æ¶¨å¹…ï¼‰ - ä»…è®­ç»ƒæ—¶è®¡ç®— ===

    if for_training:
        df['future_return'] = df['close'].shift(-5) / df['close'] - 1
        df['label'] = (df['future_return'] > 0.03).astype(int)

    return df


def predict_today():
    """ä¸»å‡½æ•°ï¼šå¢é‡æ›´æ–°æ•°æ®å¹¶é¢„æµ‹"""

    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ¯æ—¥è‚¡ç¥¨ä¸Šæ¶¨æ¦‚ç‡é¢„æµ‹")
    print(f"{'='*80}")
    print(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # 1. æ£€æŸ¥å¹¶åŠ è½½æ¨¡å‹
    model_path = 'rf_model.pkl'
    if not os.path.exists(model_path):
        print(f"\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print(f"è¯·å…ˆè¿è¡Œ final_strategy.py è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹")
        return

    print(f"\n[1/4] ğŸ“¦ åŠ è½½æ¨¡å‹...")
    with open(model_path, 'rb') as f:
        model_data = pickle.load(f)
        model = model_data['model']
        feature_cols = model_data['feature_cols']
        stock_pool = model_data['stock_pool']

    print(f"  âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"  âœ“ è‚¡ç¥¨æ± : {len(stock_pool)} åª")
    print(f"  âœ“ ç‰¹å¾æ•°: {len(feature_cols)} ä¸ª")

    # 2. ç™»å½• baostock
    print(f"\n[2/4] ğŸ” ç™»å½• baostock...")
    lg = bs.login()
    if lg.error_code != '0':
        print(f"  âŒ ç™»å½•å¤±è´¥: {lg.error_msg}")
        return
    print(f"  âœ“ ç™»å½•æˆåŠŸ")

    try:
        # 3. å¢é‡æ›´æ–°æ‰€æœ‰è‚¡ç¥¨æ•°æ®
        print(f"\n[3/4] ğŸ“ˆ å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®...")
        data_dir = 'stock_data'

        # æ˜¾ç¤ºæ¨¡å‹æœŸæœ›çš„ç‰¹å¾åˆ—è¡¨
        print(f"\n  æ¨¡å‹æœŸæœ›ç‰¹å¾ ({len(feature_cols)} ä¸ª):")
        for i, feat in enumerate(feature_cols, 1):
            print(f"    {i}. {feat}")
        print()

        predictions = []
        success_count = 0
        fail_count = 0
        first_error_shown = False  # æ ‡è®°æ˜¯å¦å·²æ˜¾ç¤ºç¬¬ä¸€ä¸ªé”™è¯¯

        total = len(stock_pool)
        for idx, (code, name) in enumerate(stock_pool.items(), 1):
            # ä½¿ç”¨ä¸ä¸‹è½½è„šæœ¬ä¸€è‡´çš„å‘½åæ ¼å¼: {code}_{name}.csv
            csv_path = os.path.join(data_dir, f'{code}_{name}.csv')

            # æ˜¾ç¤ºè¿›åº¦
            if idx % 10 == 0 or idx == 1:
                print(f"  è¿›åº¦: {idx}/{total} ({idx/total*100:.1f}%) - {code} {name}")

            # å¢é‡æ›´æ–°æ•°æ®
            df = update_stock_data_incremental(code, csv_path, max_days=10)

            if df is None or len(df) < 60:
                fail_count += 1
                if not first_error_shown:
                    print(f"\n  âš ï¸  é¦–ä¸ªå¤±è´¥æ¡ˆä¾‹: {code} {name}")
                    print(f"      åŸå› : æ•°æ®ä¸è¶³")
                    if df is None:
                        print(f"      è¯¦æƒ…: CSVæ–‡ä»¶è¯»å–å¤±è´¥æˆ–æ— æ•°æ®")
                    else:
                        print(f"      è¯¦æƒ…: æ•°æ®è¡Œæ•° {len(df)} < 60 (ä¸è¶³ä»¥è®¡ç®—æŠ€æœ¯æŒ‡æ ‡)")
                    print(f"      æ–‡ä»¶: {csv_path}")
                    first_error_shown = True
                continue

            # è®¡ç®—ç‰¹å¾
            df = calculate_features(df, for_training=False)

            # æ£€æŸ¥ç‰¹å¾åˆ—æ˜¯å¦å­˜åœ¨
            missing_cols = [col for col in feature_cols if col not in df.columns]
            if missing_cols:
                fail_count += 1
                if not first_error_shown:
                    print(f"\n  âš ï¸  é¦–ä¸ªå¤±è´¥æ¡ˆä¾‹: {code} {name}")
                    print(f"      åŸå› : ç¼ºå°‘ç‰¹å¾åˆ—")
                    print(f"      ç¼ºå¤±ç‰¹å¾: {missing_cols}")
                    print(f"      è®¡ç®—åç‰¹å¾æ•°: {len(df.columns)}")
                    first_error_shown = True
                continue

            df = df.dropna(subset=feature_cols)

            if len(df) == 0:
                fail_count += 1
                if not first_error_shown:
                    print(f"\n  âš ï¸  é¦–ä¸ªå¤±è´¥æ¡ˆä¾‹: {code} {name}")
                    print(f"      åŸå› : ç‰¹å¾è®¡ç®—åæ‰€æœ‰è¡Œéƒ½åŒ…å«NaN")
                    print(f"      åŸå§‹è¡Œæ•°: {len(calculate_features(update_stock_data_incremental(code, csv_path, max_days=10), for_training=False))}")
                    print(f"      å»é™¤NaNå: 0")
                    first_error_shown = True
                continue

            # ä½¿ç”¨æœ€æ–°ä¸€è¡Œæ•°æ®é¢„æµ‹
            latest = df.iloc[-1]
            X = latest[feature_cols].values.reshape(1, -1)

            # é¢„æµ‹æ¦‚ç‡
            prob = model.predict_proba(X)[0][1]

            predictions.append({
                'è‚¡ç¥¨ä»£ç ': code,
                'è‚¡ç¥¨åç§°': name,
                'é¢„æµ‹æ¦‚ç‡': prob,
                'æ•°æ®æ—¥æœŸ': latest['date'].strftime('%Y-%m-%d'),
                'æ”¶ç›˜ä»·': latest['close'],
                'å¼€ç›˜ä»·': latest['open'],
                'æ˜¨æ—¥æ¶¨å¹…': latest.get('return_1d_prev', 0),
                '5æ—¥æ¶¨å¹…': latest.get('return_5d_prev', 0),
                '10æ—¥æ¶¨å¹…': latest.get('return_10d_prev', 0),
                'å¼€ç›˜è·³ç©º': latest.get('open_gap', 0),
                'RSI': latest.get('rsi_prev', 50),
                'é‡æ¯”': latest.get('volume_ratio_prev', 1),
                'å¸ƒæ—å¸¦ä½ç½®': latest.get('bb_position_prev', 0.5),
                'æ³¢åŠ¨ç‡': latest.get('volatility_prev', 0)
            })

            success_count += 1

            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªæˆåŠŸæ¡ˆä¾‹çš„è¯¦ç»†ä¿¡æ¯
            if success_count == 1:
                print(f"\n  âœ… é¦–ä¸ªæˆåŠŸæ¡ˆä¾‹: {code} {name}")
                print(f"      CSVè¡Œæ•°: {len(update_stock_data_incremental(code, csv_path, max_days=10))}")
                print(f"      ç‰¹å¾è®¡ç®—å: {len(calculate_features(update_stock_data_incremental(code, csv_path, max_days=10), for_training=False))}")
                print(f"      å»é™¤NaNå: {len(df)}")
                print(f"      æœ€æ–°æ—¥æœŸ: {latest['date'].strftime('%Y-%m-%d')}")
                print(f"      é¢„æµ‹æ¦‚ç‡: {prob:.2%}\n")

        print(f"\n  âœ“ æ•°æ®æ›´æ–°å®Œæˆ: æˆåŠŸ {success_count}/{total}, å¤±è´¥ {fail_count}")

    finally:
        bs.logout()
        print(f"  âœ“ å·²ç™»å‡º baostock")

    if len(predictions) == 0:
        print(f"\nâŒ æ— æœ‰æ•ˆé¢„æµ‹æ•°æ®")
        return

    # 4. ç”ŸæˆExcelæ–‡ä»¶
    print(f"\n[4/4] ğŸ“Š ç”Ÿæˆé¢„æµ‹Excel...")

    df_predictions = pd.DataFrame(predictions)
    df_predictions = df_predictions.sort_values('é¢„æµ‹æ¦‚ç‡', ascending=False)
    df_predictions['æ’å'] = range(1, len(df_predictions) + 1)

    # è°ƒæ•´åˆ—é¡ºåº
    cols = ['æ’å', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'é¢„æµ‹æ¦‚ç‡', 'æ•°æ®æ—¥æœŸ', 'æ”¶ç›˜ä»·', 'å¼€ç›˜ä»·',
            'å¼€ç›˜è·³ç©º', 'æ˜¨æ—¥æ¶¨å¹…', '5æ—¥æ¶¨å¹…', '10æ—¥æ¶¨å¹…', 'RSI', 'é‡æ¯”', 'å¸ƒæ—å¸¦ä½ç½®', 'æ³¢åŠ¨ç‡']
    df_predictions = df_predictions[cols]

    # ä¿å­˜åˆ°Excel
    output_file = f"stock_predictions_{datetime.now().strftime('%Y%m%d')}.xlsx"

    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        # å†™å…¥å®Œæ•´é¢„æµ‹ç»“æœ
        df_predictions.to_excel(writer, sheet_name='å®Œæ•´é¢„æµ‹', index=False)

        # å†™å…¥é«˜æ¦‚ç‡è‚¡ç¥¨ï¼ˆâ‰¥60%ï¼‰
        df_high = df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.60]
        if len(df_high) > 0:
            df_high.to_excel(writer, sheet_name='é«˜æ¦‚ç‡è‚¡ç¥¨(â‰¥60%)', index=False)

        # å†™å…¥ä¸­ç­‰æ¦‚ç‡è‚¡ç¥¨ï¼ˆ55%-60%ï¼‰
        df_medium = df_predictions[(df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.55) &
                                   (df_predictions['é¢„æµ‹æ¦‚ç‡'] < 0.60)]
        if len(df_medium) > 0:
            df_medium.to_excel(writer, sheet_name='ä¸­ç­‰æ¦‚ç‡è‚¡ç¥¨(55-60%)', index=False)

    print(f"  âœ“ Excelå·²ç”Ÿæˆ: {output_file}")

    # 5. æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
    print(f"\n{'='*80}")
    print(f"ğŸ“Š é¢„æµ‹ç»“æœæ‘˜è¦")
    print(f"{'='*80}")
    print(f"æ€»è‚¡ç¥¨æ•°: {len(df_predictions)}")
    print(f"å¹³å‡é¢„æµ‹æ¦‚ç‡: {df_predictions['é¢„æµ‹æ¦‚ç‡'].mean():.2%}")
    print(f"")
    print(f"æ¦‚ç‡åˆ†å¸ƒ:")
    print(f"  â‰¥ 65%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.65])} åª")
    print(f"  â‰¥ 60%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.60])} åª")
    print(f"  â‰¥ 55%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.55])} åª")
    print(f"  â‰¥ 50%: {len(df_predictions[df_predictions['é¢„æµ‹æ¦‚ç‡'] >= 0.50])} åª")

    # æ˜¾ç¤ºTop 10
    print(f"\n{'='*80}")
    print(f"ğŸ† Top 10 é¢„æµ‹è‚¡ç¥¨")
    print(f"{'='*80}")
    print(f"{'æ’å':<6} {'ä»£ç ':<10} {'åç§°':<12} {'æ¦‚ç‡':<10} {'å¼€ç›˜ä»·':<10} {'å¼€ç›˜è·³ç©º':<10}")
    print(f"{'-'*80}")

    for _, row in df_predictions.head(10).iterrows():
        print(f"{row['æ’å']:<6} {row['è‚¡ç¥¨ä»£ç ']:<10} {row['è‚¡ç¥¨åç§°']:<12} "
              f"{row['é¢„æµ‹æ¦‚ç‡']:>8.2%} {row['å¼€ç›˜ä»·']:>9.2f} {row['å¼€ç›˜è·³ç©º']:>9.2%}")

    print(f"\n{'='*80}")
    print(f"âœ… é¢„æµ‹å®Œæˆï¼")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    predict_today()
